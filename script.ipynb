{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [22/Dec/2020 23:18:36] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator BaggingClassifier from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 0.23.1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator AdaBoostClassifier from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.23.2 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Arnav\\Anaconda3\\envs\\gpu\\lib\\site-packages\\lightgbm\\sklearn.py:680: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  X = _LGBMCheckArray(X, accept_sparse=True, force_all_finite=False)\n",
      "127.0.0.1 - - [22/Dec/2020 23:18:48] \"\u001b[37mGET /search/v2/12$23$12$12$12$12$12$3$6_23$12$12$12$12$12$3$6_1$2$3$4$5_1$2$3$4$5_1$2$3$4$5$2$3$4$5$2$3$4$1_1$2$3$4$5_1$2$3$4$5$1$2$3$4$5$1$2$3$4$5$1$2$3$4$5$1$2$3$4$5$1$2 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response, request\n",
    "from flask import render_template, make_response, redirect\n",
    "from flask_restful import Resource, Api\n",
    "import numpy as np\n",
    "import flask\n",
    "import pickle     \n",
    "import json\n",
    "import jsonify\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "token = \"u484skTfr7ZfUNcLw9lRxAhsm1IIqNmtOYyqCf_JTtBulXIC53Qv_HE4q_9H_hG3x_DZMXokvcmjkaZ0iVglGg==\"\n",
    "org = \"org\"\n",
    "bucket = \"sih\"\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True\n",
    "app.config['JSON_SORT_KEYS'] = False\n",
    "\n",
    "api = Api(app)\n",
    "# api2 = Api(app)\n",
    "\n",
    "\n",
    "def writedb(maintest):\n",
    "    try:\n",
    "        write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "        bucket = 'sih'\n",
    "        tables=['model1','model2','model3','model4','model5','model6','model7','model8']\n",
    "        for i in range(len(maintest)):\n",
    "            tname = tables[i]\n",
    "            wr = tname + ',host=host1 '\n",
    "            pp = maintest[i]\n",
    "            for l,m in pp.items():\n",
    "                s = wr + l+ '=' + str(m)\n",
    "#                 print(s)\n",
    "                write_api.write('sih', org,s)\n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "            \n",
    "def mdl1(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['room_id','no_of_occupants','indoor_temp','outdoor_temp','floor_no','ceiling_height','room_area','roof_material','humidity']\n",
    "    ret['model_id'] = 1\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')[1:]\n",
    "    roomid = ls[1]\n",
    "    floorid = ls[4]\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"model1.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['hvac_load'] = result[0]\n",
    "    return ret\n",
    "\n",
    "def hvach(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['compactness', 'surface_area', 'wall_area', 'roof_area', 'height', 'orientation', 'glazing_area', 'glazing_area_distribution']\n",
    "    ret['model_id'] = 2\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"heating_load.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['fixed_heating_load'] = result[0]\n",
    "    return ret\n",
    "\n",
    "def hvacc(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['compactness', 'surface_area', 'wall_area', 'roof_area', 'height', 'orientation', 'glazing_area', 'glazing_area_distribution']\n",
    "    ret['model_id'] = 3\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"cooling_load.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['fixed_cooling_load'] = result[0]\n",
    "    return ret\n",
    "\n",
    "def hec(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['interval1','interval2','interval3','interval4','interval5']\n",
    "    ret['model_id'] = 4\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "    x = np.asarray(to_predict, dtype='float64')\n",
    "    loaded_model = pickle.load(open(\"d2_lr.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(x)\n",
    "    ret['hourly_energy_consumption'] = str(result[0])\n",
    "    return ret\n",
    "    \n",
    "def ef(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$') # kwh kwh kwh\n",
    "    hdr = ['active_power','reactive_power','voltage','ktch','ldr']\n",
    "    ret['model_id'] = 5\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"d3_rf_1.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['hvac_load'] = str(result[0])\n",
    "    return ret\n",
    "    \n",
    "def efp(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['region_cluster','maintenance_vendor','manufacturer','equipment_type','S15','S17','S13','S5','S16','S19','S18','S8','equipment_age']\n",
    "    ret['model_id'] = 6\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"dataset5.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['equipment_health_status(faliure)'] = str(result[0])\n",
    "    return ret\n",
    "\n",
    "def epc(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['voltage', 'global_intensity','sub_meter_1', 'sub_meter_2','sub_meter_3']\n",
    "    ret['model_id'] = 7\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"dataset6_dtr.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['predicted_energy_use'] = result[0]*10\n",
    "    return ret\n",
    "\n",
    "def aep(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['temp_ktcharea','humidity_ktcharea','temp_livroom','humidity_livroom','temp_ldroom','humidity_ldroom','temp_ofroom','humidity_ofroom','temp_bthroom','humidity_bthroom','temp_outdoor','humidity_outdoor','temp_irnroom','humidity_irnroom','temp_tnroom','humidity_tnroom','temp_prroom','humidity_prroom','temp_outdoor2','pressure_outdoor2','humidity_outdoor2','wnd_speed_outdoor2','vis_outdoo2','rv1','rv2']\n",
    "    ret['model_id'] = 8\n",
    "#     print('rcv ln',len(org))\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"d7_lightgbm1.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['global_power'] = str(result[0])\n",
    "    return ret\n",
    "def efp1(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['region_cluster','maintenance_vendor','manufacturer','equipment_type','S15','S17','S13','S5','S16','S19','S18','S8','equipment_age']\n",
    "    ret['model_id'] = 5\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"dataset5.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['equipment_health_status(faliure)'] = str(result[0])\n",
    "    return ret\n",
    "\n",
    "def epc1(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['voltage', 'global_intensity','sub_meter_1', 'sub_meter_2','sub_meter_3']\n",
    "    ret['model_id'] = 6\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"dataset6_dtr.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['predicted_energy_use'] = result[0]\n",
    "    return ret\n",
    "\n",
    "def aep1(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['temp_ktcharea','humidity_ktcharea','temp_livroom','humidity_livroom','temp_ldroom','humidity_ldroom','temp_ofroom','humidity_ofroom','temp_bthroom','humidity_bthroom','temp_outdoor','humidity_outdoor','temp_irnroom','humidity_irnroom','temp_tnroom','humidity_tnroom','temp_prroom','humidity_prroom','temp_outdoor2','pressure_outdoor2','humidity_outdoor2','wnd_speed_outdoor2','vis_outdoo2','rv1','rv2']\n",
    "    ret['model_id'] = 7\n",
    "#     print('rcv ln',len(org))\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')\n",
    "#     print(ls)\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    loaded_model = pickle.load(open(\"d7_lightgbm1.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    ret['global_power'] = str(result[0])\n",
    "    return ret\n",
    "\n",
    "def mdl1n(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['room_id','no_of_occupants','indoor_temp','outdoor_temp','floor_no','ceiling_height','room_area','roof_material','humidity']\n",
    "    ret['model_id'] = 1\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')[1:]\n",
    "    roomid = ls[1]\n",
    "    floorid = ls[4]\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    lm1 = pickle.load(open(\"load_type.pkl\",\"rb\"))\n",
    "    rs1 = lm1.predict(to_predict)\n",
    "    loaded_model = pickle.load(open(\"hvac_load_new.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    rss = ''\n",
    "    if(rs1 == 0):\n",
    "            rss = 'Heating Load'\n",
    "    if(rs1 == 1):\n",
    "            rss = 'Cooling Load'\n",
    "    ret['hvac_type'] = rss\n",
    "    ret['hvac_load'] = result[0]\n",
    "    return ret\n",
    "\n",
    "def mdl1n1(txt1):\n",
    "    ret = OrderedDict()\n",
    "    org = txt1.split('$')\n",
    "    hdr = ['room_id','no_of_occupants','indoor_temp','outdoor_temp','floor_no','ceiling_height','room_area','roof_material','humidity']\n",
    "    ret['model_id'] = 1\n",
    "    for i in range(len(hdr)):\n",
    "        ret[hdr[i]] = org[i]\n",
    "    ls = txt1.split('$')[1:]\n",
    "    roomid = ls[1]\n",
    "    floorid = ls[4]\n",
    "    to_predict = np.array(ls).reshape(1,len(ls))\n",
    "#     print(to_predict)\n",
    "    lm1 = pickle.load(open(\"load_type.pkl\",\"rb\"))\n",
    "    rs1 = lm1.predict(to_predict)\n",
    "    loaded_model = pickle.load(open(\"hvac_load_new.pkl\",\"rb\"))\n",
    "    result = loaded_model.predict(to_predict)\n",
    "    rss = ''\n",
    "    if(rs1 == 0):\n",
    "            rss = 'Heating Load'\n",
    "    if(rs1 == 1):\n",
    "            rss = 'Cooling Load'\n",
    "#     ret['hvac_type'] = rss\n",
    "    ret['hvac_load'] = result[0]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def invalid(txt):\n",
    "    return 'Bad Request'\n",
    "\n",
    "class Dash(Resource):\n",
    "    pass\n",
    "res = []\n",
    "class Display(Resource):\n",
    "\n",
    "    def get(self, string1):\n",
    "        global res\n",
    "        res = []\n",
    "        txt = string1\n",
    "        tx = txt.split('_')\n",
    "        tmp = []\n",
    "        res.append(mdl1(tx[0]))\n",
    "        maintest = []\n",
    "        maintest.append(mdl1n1(tx[0]))\n",
    "        tmp.append(hvach(tx[1]))\n",
    "        tmp.append(hvacc(tx[1]))\n",
    "        tmp.append(hec(tx[2]))\n",
    "#         tmp.append('EF MODEL ERROR XGB')\n",
    "        tmp.append(ef(tx[3]))        \n",
    "        tmp.append(efp(tx[4]))\n",
    "        tmp.append(epc(tx[5]))\n",
    "#         tmp.append('AEP MODEL ERROR LGBM')\n",
    "        tmp.append(aep(tx[6]))\n",
    "        res.extend(tmp)\n",
    "        maintest.extend(tmp)\n",
    "        writedb(maintest)\n",
    "        return flask.jsonify(results = res)\n",
    "        # return invalid(txt)\n",
    "        # headers = {'Content-Type': 'text/html'}\n",
    "        # return{'text':'test'}\n",
    "        # return make_response(render_template(\"result.html\",result= \"{}\".format(string1)))\n",
    "res1 = []\n",
    "class Display2(Resource):\n",
    "\n",
    "    def get(self, string1):\n",
    "        global res1\n",
    "        res1 = []\n",
    "        txt = string1\n",
    "        tx = txt.split('_')\n",
    "        res1.append(mdl1n(tx[0]))\n",
    "        res1.append(hvach(tx[1]))\n",
    "        res1.append(hvacc(tx[1]))\n",
    "        res1.append(hec(tx[2]))\n",
    "#         res1.append('EF MODEL ERROR XGB')\n",
    "#         res1.append(ef(tx[3]))        \n",
    "        res1.append(efp1(tx[4]))\n",
    "        res1.append(epc1(tx[5]))\n",
    "#         res1.append('AEP MODEL ERROR LGBM')\n",
    "        res1.append(aep1(tx[6]))\n",
    "        maintest = res1\n",
    "#         writedb(maintest)\n",
    "        return flask.jsonify(results = res1)\n",
    "# class Dash(Resource):\n",
    "#     def get(self):\n",
    "#         return redirect(\"https://www.google.com\", code=302)\n",
    "    \n",
    "api.add_resource(Display, '/search/v1/<string:string1>')\n",
    "api.add_resource(Display2, '/search/v2/<string:string1>')\n",
    "@app.route('/dash')\n",
    "def hello():\n",
    "#     webbrowser.open_new_tab(\"https://curly-stingray-27.loca.lt/dashboard/snapshot/l63YI2RT888zDKHXWd9jFC1ifT6iZrQO?orgId=1&kiosk\")\n",
    "#     return render_template('res.html')\n",
    "    return redirect('http://139.59.57.119:3000/d/LmTA89zmk/sih-building-management-monitoring-and-control-unit?orgId=1&refresh=5s&kiosk', code = '302')\n",
    "#     return 'You have been redirected!'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(threaded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
